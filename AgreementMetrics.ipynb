{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "import re # only for use of regex flags in pandas str methods\n",
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'TermsOfService_Agreement.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9b707fe07c54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TermsOfService_Agreement.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/matt/anaconda3/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    472\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/matt/anaconda3/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/matt/anaconda3/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/matt/anaconda3/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/matt/anaconda3/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1070\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1072\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1074\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3173)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:5912)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: File b'TermsOfService_Agreement.csv' does not exist"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"TermsOfService_Agreement.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 0-1 flags for presence of special keywords\n",
    "df['Arbitration'] = (df.ParagraphText.str.contains('arbitration', flags=re.IGNORECASE)).astype('int8')\n",
    "df['ThirdParty'] = (df.ParagraphText.str.contains('third[- ]party', flags=re.IGNORECASE)).astype('int8')\n",
    "df['Waiver'] = (df.ParagraphText.str.contains('waiver', flags=re.IGNORECASE)).astype('int8')\n",
    "\n",
    "# Some more paragraph stats\n",
    "df['ParagraphWords'] = (df.ParagraphText.str.count(' ')) + 1 # a space was the best indicator of actual words I could find \n",
    "                                                             # without inserting a great deal of complication.\n",
    "df['ParagraphSentences'] = (df.ParagraphText.str.count(r'\\.[ $]')) # period followed by space or end-of-string\n",
    "df['Quotes'] = df.ParagraphText.str.count(r'[\"]')\n",
    "df['Parentheses'] = df.ParagraphText.str.count(r'[)(]') - 2*df.ParagraphText.str.count(r'\\([a-zA-Z0-9]\\)')\n",
    "df['AvgWordLength'] = (df.ParagraphLength - (df.ParagraphWords - 1) - df.ParagraphSentences - df.Quotes - \n",
    "                       df.Parentheses)/df.ParagraphWords\n",
    "#  (total chars - #spaces - #periods - #quotechars - #parentheses)/#words\n",
    "# not exact, but a good approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Company', 'ParagraphText', 'ParagraphLength', 'SpacesCount',\n",
      "       'CapsCount', 'CapToLegthRatio', 'ParaLocation', 'Import_HM',\n",
      "       'Import_KS', 'Import_MH', 'Import_JL', 'Arbitration', 'ThirdParty',\n",
      "       'Waiver', 'ParagraphWords', 'ParagraphSentences', 'Quotes',\n",
      "       'Parentheses', 'AvgWordLength'],\n",
      "      dtype='object')\n",
      "['Amazon' 'Cloudant' 'Facebook' 'GitHub' 'Google' 'Instagram' 'Netflix'\n",
      " 'SoundCloud' 'Twitter' 'Wikipedia' 'Yahoo' 'Youtube' 'iCloud']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(np.sort(df.Company.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Import_HM', 'Import_JL', 'Import_KS', 'Import_MH']\n",
      "['Amazon' 'Cloudant' 'Facebook' 'GitHub' 'Google' 'Instagram' 'Netflix'\n",
      " 'SoundCloud' 'Twitter' 'Wikipedia' 'Yahoo' 'Youtube' 'iCloud']\n"
     ]
    }
   ],
   "source": [
    "annotations = sorted(list(df.columns[df.columns.str.contains('Import')]))\n",
    "companies = np.sort(df.Company.unique())\n",
    "print(annotations)\n",
    "print(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Import_JL': ('Amazon', 'Cloudant', 'GitHub', 'Instagram', 'SoundCloud', 'Twitter'), 'Import_HM': ('Facebook', 'GitHub', 'Google', 'Twitter', 'Yahoo', 'iCloud'), 'Import_MH': ('Cloudant', 'Facebook', 'Google', 'Netflix', 'SoundCloud', 'Youtube'), 'Import_KS': ('Amazon', 'Instagram', 'Netflix', 'Yahoo', 'Youtube', 'iCloud')}\n"
     ]
    }
   ],
   "source": [
    "# Define the assignments\n",
    "assignments = {annotations[0]:tuple(companies[[2,3,4,8,10,12]]),\n",
    "               annotations[1]:tuple(companies[[0,1,3,5,7,8]]),\n",
    "               annotations[2]:tuple(companies[[0,5,6,10,11,12]]),\n",
    "               annotations[3]:tuple(companies[[1,2,4,6,7,11]])}\n",
    "print(assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import_JL:\n",
      "       Company  Import_JL  Import_HM  Import_MH  Import_KS\n",
      "595  Instagram        NaN        NaN        NaN          1\n",
      "596  Instagram        NaN        NaN        NaN          1\n",
      "597  Instagram        NaN        NaN        NaN          1\n",
      "Import_HM:\n",
      "Empty DataFrame\n",
      "Columns: [Company, Import_JL, Import_HM, Import_MH, Import_KS]\n",
      "Index: []\n",
      "Import_MH:\n",
      "        Company  Import_JL  Import_HM  Import_MH  Import_KS\n",
      "461  SoundCloud          0        NaN        NaN        NaN\n",
      "572    Cloudant          0        NaN        NaN        NaN\n",
      "740    Facebook        NaN          0        NaN        NaN\n",
      "Import_KS:\n",
      "Empty DataFrame\n",
      "Columns: [Company, Import_JL, Import_HM, Import_MH, Import_KS]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Inspect null values\n",
    "nulls = {}\n",
    "for name in list(assignments.keys()):\n",
    "    a = df[name][df.Company.isin(assignments[name])]\n",
    "    a = a[a.isnull()]\n",
    "    nulls[name] = a.index\n",
    "    \n",
    "for name in list(nulls.keys()):\n",
    "    indices = nulls[name]\n",
    "    print(name + \":\")\n",
    "    print(df.loc[indices, ['Company'] + list(nulls.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Company  Import_JL  Import_HM  Import_MH  Import_KS\n",
      "595  Instagram          1        NaN        NaN          1\n",
      "596  Instagram          1        NaN        NaN          1\n",
      "597  Instagram          1        NaN        NaN          1\n",
      "Empty DataFrame\n",
      "Columns: [Company, Import_JL, Import_HM, Import_MH, Import_KS]\n",
      "Index: []\n",
      "        Company  Import_JL  Import_HM  Import_MH  Import_KS\n",
      "461  SoundCloud          0        NaN          0        NaN\n",
      "572    Cloudant          0        NaN          0        NaN\n",
      "740    Facebook        NaN          0          0        NaN\n",
      "Empty DataFrame\n",
      "Columns: [Company, Import_JL, Import_HM, Import_MH, Import_KS]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Reassign nulls to values in neighboring annotation columns\n",
    "for name in list(nulls.keys()):\n",
    "    indices = nulls[name]\n",
    "    df.loc[indices, name] = np.all(df.loc[indices, list(nulls.keys())].values, axis = 1).astype('int8')\n",
    "    #print(np.all(df.loc[indices, list(nulls.keys())].values, axis = 1).astype('int8'))\n",
    "    print(df.loc[indices, ['Company'] + list(nulls.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     VI  cohen companies  sampleSize\n",
      "rater1    rater2                                    \n",
      "Import_JL Import_HM NaN    NaN       b''         NaN\n",
      "          Import_MH NaN    NaN       b''         NaN\n",
      "          Import_KS NaN    NaN       b''         NaN\n",
      "Import_HM Import_MH NaN    NaN       b''         NaN\n",
      "          Import_KS NaN    NaN       b''         NaN\n",
      "Import_MH Import_KS NaN    NaN       b''         NaN\n"
     ]
    }
   ],
   "source": [
    "# Initialize agreement metric matrices\n",
    "nrows = len(assignments)*(len(assignments) - 1)/2\n",
    "\n",
    "index = pd.MultiIndex(levels=[list(assignments.keys()), list(assignments.keys())], names = ['rater1','rater2'], labels = [[0,0,0,1,1,2],[1,2,3,2,3,3]])\n",
    "metrics = pd.DataFrame({\"sampleSize\":np.NaN, \"VI\":np.NaN, \"cohen\":np.NaN, \"companies\":np.array(\"\",dtype='S32')}, index = index)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import_JL Import_HM:\n",
      "Actual:\n",
      "[[ 0.615  0.096]\n",
      " [ 0.058  0.231]]\n",
      "Independent:\n",
      "[[ 0.479  0.233]\n",
      " [ 0.194  0.094]]\n",
      "Import_JL Import_MH:\n",
      "Actual:\n",
      "[[ 0.828  0.039]\n",
      " [ 0.01   0.123]]\n",
      "Independent:\n",
      "[[ 0.727  0.14 ]\n",
      " [ 0.111  0.021]]\n",
      "Import_JL Import_KS:\n",
      "Actual:\n",
      "[[ 0.761  0.068]\n",
      " [ 0.023  0.148]]\n",
      "Independent:\n",
      "[[ 0.65   0.179]\n",
      " [ 0.134  0.037]]\n",
      "Import_HM Import_MH:\n",
      "Actual:\n",
      "[[ 0.686  0.05 ]\n",
      " [ 0.129  0.136]]\n",
      "Independent:\n",
      "[[ 0.599  0.137]\n",
      " [ 0.215  0.049]]\n",
      "Import_HM Import_KS:\n",
      "Actual:\n",
      "[[ 0.775  0.076]\n",
      " [ 0.012  0.137]]\n",
      "Independent:\n",
      "[[ 0.67   0.181]\n",
      " [ 0.117  0.032]]\n",
      "Import_MH Import_KS:\n",
      "Actual:\n",
      "[[ 0.76   0.127]\n",
      " [ 0.02   0.093]]\n",
      "Independent:\n",
      "[[ 0.692  0.195]\n",
      " [ 0.088  0.025]]\n",
      "                           VI     cohen                   companies  \\\n",
      "rater1    rater2                                                      \n",
      "Import_JL Import_HM  0.592276  0.639515       {'Twitter', 'GitHub'}   \n",
      "          Import_MH  0.243568  0.804934  {'SoundCloud', 'Cloudant'}   \n",
      "          Import_KS  0.389616  0.709331     {'Instagram', 'Amazon'}   \n",
      "Import_HM Import_MH  0.598093  0.492459      {'Google', 'Facebook'}   \n",
      "          Import_KS  0.360572  0.703700         {'Yahoo', 'iCloud'}   \n",
      "Import_MH Import_KS  0.475671  0.482596      {'Netflix', 'Youtube'}   \n",
      "\n",
      "                     sampleSize  \n",
      "rater1    rater2                 \n",
      "Import_JL Import_HM         104  \n",
      "          Import_MH         204  \n",
      "          Import_KS          88  \n",
      "Import_HM Import_MH         140  \n",
      "          Import_KS         249  \n",
      "Import_MH Import_KS         150  \n"
     ]
    }
   ],
   "source": [
    "# Compute the agreement metrics and put in a dataframe\n",
    "max_variation = np.log(4)\n",
    "for i in range(0,(len(assignments)-1)):\n",
    "        for j in range((i+1),len(assignments)):\n",
    "                name1 = list(assignments.keys())[i]\n",
    "                name2 = list(assignments.keys())[j]\n",
    "                \n",
    "                matrix = pd.crosstab(df[name1],df[name2])\n",
    "                total = matrix.values.sum()\n",
    "                proportions = matrix.values/total\n",
    "                \n",
    "                margin1 = np.add.reduce(proportions, axis=0)\n",
    "                margin2 = np.add.reduce(proportions, axis=1)\n",
    "                independent = np.zeros(shape = [len(margin1), len(margin2)], dtype = 'float')\n",
    "                for k in range(0, len(margin2)):\n",
    "                    independent[k,:] = margin1*margin2[k]\n",
    "                print(name1 + \" \" + name2 + \":\")\n",
    "                print(\"Actual:\")\n",
    "                print(proportions.round(3))\n",
    "                print(\"Independent:\")\n",
    "                print(independent.round(3))\n",
    "                \n",
    "                random = independent.diagonal()\n",
    "                actual = proportions.diagonal()\n",
    "                kappa = (np.sum(actual) - np.sum(random))/(1 - np.sum(random))\n",
    "                \n",
    "                entropy1 = -1*np.sum(margin1*np.log(margin1))\n",
    "                entropy2 = -1*np.sum(margin2*np.log(margin2))\n",
    "                mutualInformation = np.sum(proportions*np.log(proportions/independent))\n",
    "                variation = (entropy1 + entropy2 - 2*mutualInformation)/max_variation\n",
    "                \n",
    "                metrics.loc[(name1,name2),['cohen','VI','sampleSize','companies']] = [kappa,variation,total,\n",
    "                                                                                      str(set(assignments[name1]).intersection(set(assignments[name2])))]\n",
    "                \n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the final response column(s)\n",
    "df['responseAND'] = np.array(np.int(), dtype = 'int8')\n",
    "df['responseOR'] = np.array(np.int(), dtype = 'int8')\n",
    "for i in range(0,df.shape[0]):\n",
    "    # The intersection of the positive labels (AND)\n",
    "    df.loc[i,\"responseAND\"] = np.min(df.ix[i][list(assignments.keys())].dropna().values)\n",
    "    # The union of the positive labels (OR)\n",
    "    df.loc[i,\"responseOR\"] = np.max(df.ix[i][list(assignments.keys())].dropna().values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write data to csv\n",
    "df.to_csv(\"TermsOfService.csv\", index=False)\n",
    "metrics.reset_index().to_csv(\"AgreementMetrics.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
